{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "## Author: Emily McAfee\n",
    "### Bad v. Good connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are involved in a project where you are tasked to build a machine learning algorithm that distinguishes between \"bad'' connections (called intrusions or attacks) and \"good'' (normal) connections. Note that the number of normal connections is greater than that of bad ones. The following code trains a moodel to predict 'bad' connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file name\n",
    "filename = 'https://library.startlearninglabs.uw.edu/DATASCI420/2019/Datasets/Intrusion%20Detection.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "cdf = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        181       5450     0   \n",
       "1         0           tcp    http   SF        239        486     0   \n",
       "2         0           tcp    http   SF        235       1337     0   \n",
       "3         0           tcp    http   SF        219       1337     0   \n",
       "4         0           tcp    http   SF        217       2032     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                   9   \n",
       "1               0       0    0  ...                  19   \n",
       "2               0       0    0  ...                  29   \n",
       "3               0       0    0  ...                  39   \n",
       "4               0       0    0  ...                  49   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                     1.0                     0.0   \n",
       "1                     1.0                     0.0   \n",
       "2                     1.0                     0.0   \n",
       "3                     1.0                     0.0   \n",
       "4                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.11                          0.0   \n",
       "1                         0.05                          0.0   \n",
       "2                         0.03                          0.0   \n",
       "3                         0.03                          0.0   \n",
       "4                         0.02                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  Class  \n",
       "0                       0.0      0  \n",
       "1                       0.0      0  \n",
       "2                       0.0      0  \n",
       "3                       0.0      0  \n",
       "4                       0.0      0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['http', 'smtp', 'finger', 'domain_u', 'auth', 'telnet', 'ftp',\n",
       "       'eco_i', 'ntp_u', 'ecr_i', 'other', 'pop_3', 'ftp_data', 'ssh',\n",
       "       'domain', 'private', 'time', 'shell', 'IRC', 'urh_i', 'X11',\n",
       "       'urp_i', 'tftp_u', 'tim_i', 'red_i'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "#cdf.dtypes\n",
    "#sum(cdf.Class)\n",
    "#len(cdf.Class)\n",
    "\n",
    "# Check how many groups there are in 'object' features\n",
    "#cdf.protocol_type.unique()\n",
    "#cdf.flag.unique()\n",
    "cdf.service.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http        61886\n",
       "smtp         9598\n",
       "private      7366\n",
       "domain_u     5862\n",
       "other        5632\n",
       "ftp_data     3806\n",
       "urp_i         537\n",
       "finger        468\n",
       "eco_i         389\n",
       "ntp_u         380\n",
       "ftp           374\n",
       "ecr_i         345\n",
       "telnet        240\n",
       "auth          220\n",
       "pop_3          79\n",
       "time           52\n",
       "IRC            42\n",
       "urh_i          14\n",
       "X11             9\n",
       "domain          3\n",
       "tim_i           2\n",
       "shell           1\n",
       "ssh             1\n",
       "red_i           1\n",
       "tftp_u          1\n",
       "Name: service, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further check service data to see if groups can be reduced\n",
    "cdf.service.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['http', 'smtp', 'other', 'domain_u', 'ftp_data', 'private'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce groups in 'service' feature to avoid overfitting to training data\n",
    "cdf2 = cdf.copy()\n",
    "cdf2.service = np.where(cdf2['service'] == 'urp_i', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'finger', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'eco_i', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'ntp_u', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'ftp', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'ecr_i', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'telnet', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'auth', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'pop_3', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'time', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'IRC', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'urh_i', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'X11', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'domain', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'tim_i', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'red_i', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'tftp_u', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'ssh', 'other', cdf2['service'])\n",
    "cdf2.service = np.where(cdf2['service'] == 'shell', 'other', cdf2['service'])\n",
    "\n",
    "cdf2.service.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                         int64\n",
       "protocol_type                   object\n",
       "service                         object\n",
       "flag                            object\n",
       "src_bytes                        int64\n",
       "dst_bytes                        int64\n",
       "land                             int64\n",
       "wrong_fragment                   int64\n",
       "urgent                           int64\n",
       "hot                              int64\n",
       "num_failed_logins                int64\n",
       "logged_in                        int64\n",
       "num_compromised                  int64\n",
       "root_shell                       int64\n",
       "su_attempted                     int64\n",
       "num_root                         int64\n",
       "num_file_creations               int64\n",
       "num_shells                       int64\n",
       "num_access_files                 int64\n",
       "num_outbound_cmds                int64\n",
       "is_host_login                    int64\n",
       "is_guest_login                   int64\n",
       "count                            int64\n",
       "srv_count                        int64\n",
       "serror_rate                    float64\n",
       "srv_serror_rate                float64\n",
       "rerror_rate                    float64\n",
       "srv_rerror_rate                float64\n",
       "same_srv_rate                  float64\n",
       "diff_srv_rate                  float64\n",
       "srv_diff_host_rate             float64\n",
       "dst_host_count                   int64\n",
       "dst_host_srv_count               int64\n",
       "dst_host_same_srv_rate         float64\n",
       "dst_host_diff_srv_rate         float64\n",
       "dst_host_same_src_port_rate    float64\n",
       "dst_host_srv_diff_host_rate    float64\n",
       "dst_host_serror_rate           float64\n",
       "dst_host_srv_serror_rate       float64\n",
       "dst_host_rerror_rate           float64\n",
       "dst_host_srv_rerror_rate       float64\n",
       "Class                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show which variables are categorical\n",
    "cdf2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                         int64\n",
       "src_bytes                        int64\n",
       "dst_bytes                        int64\n",
       "land                             int64\n",
       "wrong_fragment                   int64\n",
       "urgent                           int64\n",
       "hot                              int64\n",
       "num_failed_logins                int64\n",
       "logged_in                        int64\n",
       "num_compromised                  int64\n",
       "root_shell                       int64\n",
       "su_attempted                     int64\n",
       "num_root                         int64\n",
       "num_file_creations               int64\n",
       "num_shells                       int64\n",
       "num_access_files                 int64\n",
       "num_outbound_cmds                int64\n",
       "is_host_login                    int64\n",
       "is_guest_login                   int64\n",
       "count                            int64\n",
       "srv_count                        int64\n",
       "serror_rate                    float64\n",
       "srv_serror_rate                float64\n",
       "rerror_rate                    float64\n",
       "srv_rerror_rate                float64\n",
       "same_srv_rate                  float64\n",
       "diff_srv_rate                  float64\n",
       "srv_diff_host_rate             float64\n",
       "dst_host_count                   int64\n",
       "dst_host_srv_count               int64\n",
       "dst_host_same_srv_rate         float64\n",
       "dst_host_diff_srv_rate         float64\n",
       "dst_host_same_src_port_rate    float64\n",
       "dst_host_srv_diff_host_rate    float64\n",
       "dst_host_serror_rate           float64\n",
       "dst_host_srv_serror_rate       float64\n",
       "dst_host_rerror_rate           float64\n",
       "dst_host_srv_rerror_rate       float64\n",
       "Class                            int64\n",
       "protocol_type_icmp               uint8\n",
       "protocol_type_tcp                uint8\n",
       "protocol_type_udp                uint8\n",
       "service_domain_u                 uint8\n",
       "service_ftp_data                 uint8\n",
       "service_http                     uint8\n",
       "service_other                    uint8\n",
       "service_private                  uint8\n",
       "service_smtp                     uint8\n",
       "flag_OTH                         uint8\n",
       "flag_REJ                         uint8\n",
       "flag_RSTO                        uint8\n",
       "flag_RSTR                        uint8\n",
       "flag_S0                          uint8\n",
       "flag_S1                          uint8\n",
       "flag_S2                          uint8\n",
       "flag_S3                          uint8\n",
       "flag_SF                          uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables for categorical variables\n",
    "cdf3 = cdf2.copy()\n",
    "protocol_type = pd.get_dummies(cdf3['protocol_type'], prefix = 'protocol_type')\n",
    "service = pd.get_dummies(cdf3['service'], prefix = 'service')\n",
    "flag = pd.get_dummies(cdf3['flag'], prefix = 'flag')\n",
    "\n",
    "# Bring together in one big dataframe\n",
    "cdf3 = pd.concat([cdf3, protocol_type, service, flag], axis = 1)\n",
    "\n",
    "# Get rid of old categorical columns\n",
    "cdf4 = cdf3.drop(['protocol_type','service', 'flag'], axis = 1)\n",
    "\n",
    "# Check new data frame\n",
    "cdf4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish features\n",
    "x = cdf4.loc[:, cdf4.columns != 'Class']\n",
    "#x = x2.drop(['serror_rate', 'rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_count',\n",
    "          #'srv_serror_rate', 'srv_rerror_rate', 'srv_diff_host_rate'], axis = 1)\n",
    "\n",
    "# Establish target label (variabel we are trying to predict)\n",
    "y = cdf4.Class\n",
    "# y = y.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the model\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e.kubicek/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start model\n",
    "logreg = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "# Fit model with data\n",
    "logreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Determine your model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how well we predicted with accuracy (with class imbalances)\n",
    "y_pred = logreg.predict(x_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how well we predicted with conofusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modify data by handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What did our imbalance look like before SMOTE\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_sample(x, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use the same model on updated (balanced) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test for SMOTE data\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_res,y_res,test_size=0.25,random_state=0)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model with now balanced data\n",
    "logreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New accuracy\n",
    "y_pred=logreg.predict(x_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))\n",
    "\n",
    "# New confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information in ROC curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Describe your findings\n",
    "The data we are working with here contains information on connections between computers. We wanted to know if we could predict which connections are 'bad' so that we can avoid getting hacked or viruses. Since, luckily, there are far more successful and 'good' connections than bad ones, this means that we have a major class imbalance with our data. However, in order to see the impact a class imbalance can have on a model, we applied a logistic regression model to the imbalanced data.\n",
    "\n",
    "When doing this, we found a 99% (wow!) accuracy rate in predicting the connection type. However, the large discrepency between the samples means that the model will tend to favor the larger sample (in this case the'good' connections. Meaning, even if the model only pays attention to those cases, the accuracy will still be very high. We can see this situation demonstrated in the confusion matrix, where we can see that we got zero correct predictions in regards to 'bad' connections - which is not good for us, since that is the entire point of the model. To improve the model we can implement a SMOTE algorithm. By creating synthetic samples oof our minority data, we can properly balance the two samples. After this balancing, we can see that our model performs very well (93%) on our test data and has a more reasonable confusion matrix. This information is echoed within the ROC visualization, where we can see that our curve (blue) is far away from what would be a purely random classifier (red dotted)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
